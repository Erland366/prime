name_model = "150M"
project = "150m_zeroband_adaptive"
type_model = "llama2"
metric_logger_type = "tensorboard,wandb"
run_name = "binned_warmup"

[train]
micro_bs = 16 # change this base on the gpu

[data]
num_workers = 1
dataset_name_or_paths = "datasets/fineweb-edu/data"

[experiment]
fsdp = false
inner_scheduler_type = "binned"
inner_scheduler_lower_steps = 10
inner_scheduler_upper_steps = 2000
inner_scheduler_bin_size = 10
warmup = true
inner_warmup_steps = 200

[optim]
batch_size = 512
warmup_steps = 500
total_steps = 1024

[diloco]
inner_steps = 10
compression = "no"

[optim.optim]
lr = 5e-5
