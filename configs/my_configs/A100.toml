name_model = "150M"
project = "debug_150m_zero_band_without_fsdp_diloco"
type_model = "llama2"
metric_logger_type = "wandb,tensorboard"

[train]
micro_bs = 8 # change this base on the gpu

[data]
num_workers = 1
dataset_name_or_paths = "datasets/fineweb-edu/data"

[optim]
batch_size = 512
warmup_steps = 500
total_steps = 8192

[diloco]
inner_steps = 10

[optim.optim]
lr = 4e-4
